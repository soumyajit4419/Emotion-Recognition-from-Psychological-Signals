{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_SFTT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KX9JebafQwrI",
        "outputId": "78667e30-68cd-46f6-f530-d571aea50efa"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxJjXR3URAea"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader,TensorDataset,random_split\n",
        "from torchvision.transforms import transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX_dmuAPRAgd"
      },
      "source": [
        "class SFTT(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2),\n",
        "\n",
        "        nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.AdaptiveAvgPool2d(1),\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(256,128),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(128,64),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(64,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self,xb):\n",
        "    out = self.network(xb)\n",
        "    return out\n",
        "  \n",
        "  def training_step(self,batch):\n",
        "    features,label = batch\n",
        "    out = self(features)\n",
        "    loss = F.binary_cross_entropy(out,label)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self,batch):\n",
        "    features,label = batch\n",
        "    out = self(features)\n",
        "    loss = F.binary_cross_entropy(out,label)\n",
        "    acc = accuracy(out,label)\n",
        "    return {\"val_loss\": loss.detach(),\"val_acc\": acc}\n",
        "\n",
        "  def validation_epoch_end(self,outputs):\n",
        "    batch_loss = [x['val_loss'] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_loss).mean()\n",
        "    batch_acc = [x['val_acc'] for x in outputs]\n",
        "    epoch_acc = torch.stack(batch_acc).mean()\n",
        "    return {\"val_loss\":epoch_loss.item(),\"val_acc\":epoch_acc.item()}\n",
        "\n",
        "  def epoch_end(self,num_epoch,results):\n",
        "    print(\"num_epoch: {}, train_loss: {:.2f}, val_loss: {:.2f}, val_acc: {:.2f}\".format(num_epoch+1,results['train_loss'],results['val_loss'], results['val_acc']))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_qpGIGcRrnt"
      },
      "source": [
        "def accuracy(out,label):\n",
        "  out = (out>0.5)\n",
        "  pred = (out == label).sum()\n",
        "  return pred/out.shape[0]\n",
        "\n",
        "def evaluate(model,val_loader):\n",
        "  outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(num_epochs,lr,train_loader,val_loader,model,opt_func=torch.optim.Adam):\n",
        "  optimizer = opt_func(model.parameters(),lr)\n",
        "  history = []\n",
        "  for epoch in range(num_epochs):\n",
        "    train_losses = []\n",
        "    for batch in train_loader:\n",
        "      loss = model.training_step(batch)\n",
        "      train_losses.append(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    results = evaluate(model,val_loader)\n",
        "    train_loss = torch.stack(train_losses).mean().item()\n",
        "    results['train_loss'] = train_loss\n",
        "    model.epoch_end(epoch,results)\n",
        "    history.append(results)\n",
        "  return history"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkWl66m-WvlI"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fniNBiZdWySs",
        "outputId": "2960d776-baf1-4882-d977-e5cbebcc83c0"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZWMo2LQXGYj"
      },
      "source": [
        "model = SFTT()\n",
        "model = model.to(device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1lw1SIHW23Q"
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5HwvdzzXRLw"
      },
      "source": [
        "history = fit()"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}