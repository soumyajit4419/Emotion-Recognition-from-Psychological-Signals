{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pywt\n",
    "import os\n",
    "import pickle\n",
    "import re \n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit,LeaveOneOut,KFold\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('.')\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Fourier import fourier_feature_fusion as eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Wavelet import wavelet_feature_fusion as wff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_folder = \"FusedDataSlidingWindowNew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_no=2\n",
    "user_folder='../../../User2/'\n",
    "last_index_even=41 # For even user numbers\n",
    "last_index_odd=40  # For odd user numbers\n",
    "increment=2        # Number for the increment of the user numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(label):\n",
    "    new_label=[]\n",
    "    for i in range(len(label)):\n",
    "        if(label[i]>4.5):\n",
    "            new_label.append(1)\n",
    "        else:\n",
    "            new_label.append(0)\n",
    "    return new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "def clean_data(dataset, target):\n",
    "    del_rows = []\n",
    "    for i in range(len(dataset)):\n",
    "        if(np.isnan(dataset[i]).sum() > 0):\n",
    "            del_rows.append(i)\n",
    "            \n",
    "    dataset = np.delete(dataset, del_rows, axis=0)\n",
    "    target = np.delete(target, del_rows, axis=0)\n",
    "    \n",
    "    return dataset,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 512\n",
    "step_size = 512\n",
    "User_nums = ['26']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal=[]\n",
    "valence=[]\n",
    "dominance=[]\n",
    "liking=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_features(user_no, window_size,step_size):\n",
    "    \n",
    "    ar_dict = {}\n",
    "    val_dict = {}\n",
    "    dom_dict = {}\n",
    "    lik_dict = {}\n",
    "    \n",
    "    user_folder='../../../User'+ str(user_no) + '/'\n",
    "    \n",
    "    user_csv= os.listdir(user_folder)\n",
    "    \n",
    "    user_csv = user_csv[1:]\n",
    "    \n",
    "    user_labels_folder = user_folder + 'Label/'\n",
    "    \n",
    "    user_labels=os.listdir(user_labels_folder)\n",
    "    \n",
    "    all_data=[]\n",
    "    all_labels=[]\n",
    "    \n",
    "    for csv in user_csv:\n",
    "        all_data.append(csv)\n",
    "    \n",
    "    for lab in user_labels:\n",
    "        all_labels.append(lab)\n",
    "        \n",
    "    final_features=[]\n",
    "    final_labels=[]\n",
    "        \n",
    "    for i in range(0,len(all_data)):\n",
    "        \n",
    "        data = pd.read_csv(user_folder + all_data[i])\n",
    "        cols = data.columns\n",
    "        cols = cols[:14]\n",
    "        labels=pd.read_csv(user_labels_folder + all_labels[i])\n",
    "        labels=labels.values[0][:4]\n",
    "        \n",
    "        start = 0;\n",
    "        while start + window_size < data.shape[0]:\n",
    "            \n",
    "            temp_array = []\n",
    "            temp_data = [] \n",
    "            \n",
    "            for i in cols:\n",
    "                X = data[i][start : start + window_size]\n",
    "                features_fourier = eff.power_spectrum(X)\n",
    "                features_wavelet = wff.wavelet_energy(X)\n",
    "                features_fourier = np.array(features_fourier).ravel()\n",
    "                features_wavelet = np.array(features_wavelet).ravel()\n",
    "                temp_array.append(np.concatenate((features_fourier,features_wavelet),axis=0).ravel())\n",
    "                  \n",
    "            temp_array=np.array(temp_array).ravel()\n",
    "            final_features.append(temp_array) \n",
    "            final_labels.append(labels)\n",
    "            start = start + step_size\n",
    "                \n",
    "    final_features = np.array(final_features)\n",
    "    final_labels = np.array(final_labels)\n",
    "#     print(final_features.shape)\n",
    "#     print(final_labels.shape)\n",
    "    \n",
    "    arousal_dataset=final_features\n",
    "    valence_dataset=final_features\n",
    "    dominance_dataset=final_features\n",
    "    liking_dataset=final_features\n",
    "    \n",
    "    arousal_labels=final_labels[:,0]\n",
    "    valence_labels=final_labels[:,1]\n",
    "    dominance_labels=final_labels[:,2]\n",
    "    liking_labels=final_labels[:,3]\n",
    "    \n",
    "    \n",
    "    arousal_dataset,arousal_labels = clean_data(arousal_dataset,arousal_labels)\n",
    "    valence_dataset,valence_labels = clean_data(valence_dataset,valence_labels)\n",
    "    dominance_dataset ,dominance_labels = clean_data(dominance_dataset,dominance_labels)\n",
    "    liking_dataset,liking_labels = clean_data(liking_dataset,liking_labels)\n",
    "    \n",
    "    \n",
    "    arousal_labels = getLabel(arousal_labels)\n",
    "    valence_labels = getLabel(valence_labels)\n",
    "    dominance_labels = getLabel(dominance_labels)\n",
    "    liking_labels = getLabel(liking_labels)\n",
    "    \n",
    "    ar_count=len(set(arousal_labels))\n",
    "    if ar_count==1:\n",
    "        ar_dict[user_no]=['Accuracy: '+str(100),'F1-Score: '+str(1)]\n",
    "    \n",
    "    else:\n",
    "        sm1 = SMOTE()\n",
    "        arousal_dataset,arousal_labels = sm1.fit_resample(arousal_dataset,arousal_labels)\n",
    "        x_a_train,x_a_test,y_a_train,y_a_test = train_test_split(arousal_dataset,arousal_labels,test_size=0.3,random_state=42)\n",
    "        ar_model = SVC(kernel=\"rbf\",C = 10)\n",
    "        ar_model.fit(x_a_train,y_a_train)\n",
    "        pred_a = ar_model.predict(x_a_test)\n",
    "        ar_acc=accuracy_score(pred_a,y_a_test)\n",
    "        ar_f1=f1_score(y_a_test, pred_a, average='macro')\n",
    "        \n",
    "        ar_dict[user_no]=['Accuracy: '+str(ar_acc),'F1-Score: '+str(ar_f1)]\n",
    "        arousal.append(ar_dict)\n",
    "        \n",
    "        \n",
    "    val_count=len(set(valence_labels))\n",
    "    if val_count==1:\n",
    "        val_dict[user_no]=['Accuracy: '+str(100),'F1-Score: '+str(1)]\n",
    "        \n",
    "    else:\n",
    "        sm2 = SMOTE()\n",
    "        valence_dataset,valence_labels = sm2.fit_resample(valence_dataset,valence_labels)\n",
    "        x_v_train,x_v_test,y_v_train,y_v_test = train_test_split(valence_dataset,valence_labels,test_size=0.3,random_state=42)\n",
    "        val_model = SVC(kernel=\"rbf\",C = 10)\n",
    "        val_model.fit(x_v_train,y_v_train)\n",
    "        pred_v = val_model.predict(x_v_test)\n",
    "        val_acc=accuracy_score(pred_v,y_v_test)\n",
    "        val_f1=f1_score(y_v_test, pred_v, average='macro')\n",
    "        \n",
    "        val_dict[user_no]=['Accuracy: '+str(val_acc),'F1-Score: '+str(val_f1)]\n",
    "        valence.append(val_dict)\n",
    "        \n",
    "        \n",
    "    dom_count=len(set(dominance_labels))\n",
    "    if dom_count==1:\n",
    "        dom_dict[user_no]=['Accuracy: '+str(100),'F1-Score: '+str(1)]\n",
    "    \n",
    "    else:\n",
    "        sm3 = SMOTE()\n",
    "        dominance_dataset,dominance_labels = sm3.fit_resample(dominance_dataset,dominance_labels)\n",
    "        x_d_train,x_d_test,y_d_train,y_d_test = train_test_split(dominance_dataset,dominance_labels,test_size = 0.3,random_state = 42)\n",
    "        dom_model = SVC(kernel=\"rbf\",C = 10)\n",
    "        dom_model.fit(x_d_train,y_d_train)\n",
    "        pred_d = dom_model.predict(x_d_test)\n",
    "        dom_acc=accuracy_score(pred_d,y_d_test)\n",
    "        dom_f1=f1_score(y_d_test, pred_d, average='macro')\n",
    "        \n",
    "        dom_dict[user_no]=['Accuracy: '+str(dom_acc),'F1-Score: '+str(dom_f1)]\n",
    "        dominance.append(dom_dict)\n",
    "        \n",
    "    \n",
    "    lik_count=len(set(liking_labels))\n",
    "    if lik_count==1:\n",
    "        lik_dict[user_no]=['Accuracy: '+str(100),'F1-Score: '+str(1)]\n",
    "\n",
    "    else:\n",
    "        sm4 = SMOTE()\n",
    "        liking_dataset,liking_labels = sm4.fit_resample(liking_dataset,liking_labels)\n",
    "        x_l_train,x_l_test,y_l_train,y_l_test = train_test_split(liking_dataset,liking_labels,test_size = 0.3,random_state = 42)\n",
    "        lik_model = SVC(kernel=\"rbf\",C = 10)\n",
    "        lik_model.fit(x_l_train,y_l_train)\n",
    "        pred_l = lik_model.predict(x_l_test)\n",
    "        lik_acc=accuracy_score(pred_l,y_l_test)\n",
    "        lik_f1=f1_score(y_l_test, pred_l, average='macro')\n",
    " \n",
    "        lik_dict[user_no]=['Accuracy: '+str(lik_acc),'F1-Score: '+str(lik_f1)]\n",
    "        liking.append(lik_dict)\n",
    "    \n",
    "    \n",
    "    print('User:' + str(user_no)+ \" \"+\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:2 Done\n",
      "User:4 Done\n",
      "User:6 Done\n",
      "User:8 Done\n",
      "User:10 Done\n",
      "User:12 Done\n",
      "User:14 Done\n",
      "User:16 Done\n",
      "User:18 Done\n",
      "User:20 Done\n",
      "User:22 Done\n",
      "User:24 Done\n",
      "User:26 Done\n",
      "User:28 Done\n",
      "User:30 Done\n",
      "User:32 Done\n",
      "User:34 Done\n",
      "User:36 Done\n",
      "User:38 Done\n",
      "User:40 Done\n"
     ]
    }
   ],
   "source": [
    "for i in range(user_no,last_index_even,2):\n",
    "    get_full_features(i,window_size,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: ['Accuracy: 0.8918558077436582', 'F1-Score: 0.8916820359185219']},\n",
       " {4: ['Accuracy: 0.9656319290465631', 'F1-Score: 0.9656315488664508']},\n",
       " {6: ['Accuracy: 0.9776536312849162', 'F1-Score: 0.9776502552116109']},\n",
       " {8: ['Accuracy: 0.9468085106382979', 'F1-Score: 0.9461996336996337']},\n",
       " {10: ['Accuracy: 0.9593984962406015', 'F1-Score: 0.9592791583225417']},\n",
       " {12: ['Accuracy: 0.9661214953271028', 'F1-Score: 0.9661177498276816']},\n",
       " {14: ['Accuracy: 0.908284023668639', 'F1-Score: 0.908271176944357']},\n",
       " {16: ['Accuracy: 0.9278074866310161', 'F1-Score: 0.9277992277992277']},\n",
       " {18: ['Accuracy: 0.972936400541272', 'F1-Score: 0.9729339720769422']},\n",
       " {20: ['Accuracy: 0.9082969432314411', 'F1-Score: 0.9082689556509299']},\n",
       " {22: ['Accuracy: 0.992867332382311', 'F1-Score: 0.9928644863142679']},\n",
       " {24: ['Accuracy: 0.9439252336448598', 'F1-Score: 0.9438811188811189']},\n",
       " {26: ['Accuracy: 0.932806324110672', 'F1-Score: 0.9327596359789536']},\n",
       " {32: ['Accuracy: 0.945273631840796', 'F1-Score: 0.9452519499814287']},\n",
       " {34: ['Accuracy: 0.9193548387096774', 'F1-Score: 0.9193447821970426']},\n",
       " {36: ['Accuracy: 0.9956427015250545', 'F1-Score: 0.9956426808429846']},\n",
       " {38: ['Accuracy: 0.961038961038961', 'F1-Score: 0.9610387438058']},\n",
       " {40: ['Accuracy: 0.9298013245033112', 'F1-Score: 0.9297934420074355']}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: ['Accuracy: 0.8746031746031746', 'F1-Score: 0.8745320476460579']},\n",
       " {4: ['Accuracy: 0.8653061224489796', 'F1-Score: 0.8645751327448451']},\n",
       " {6: ['Accuracy: 0.9327102803738317', 'F1-Score: 0.9325384593829686']},\n",
       " {8: ['Accuracy: 0.6818181818181818', 'F1-Score: 0.6805244378059911']},\n",
       " {10: ['Accuracy: 0.8773946360153256', 'F1-Score: 0.8773298083278255']},\n",
       " {12: ['Accuracy: 0.90625', 'F1-Score: 0.9053587960118301']},\n",
       " {14: ['Accuracy: 0.7971602434077079', 'F1-Score: 0.7970191040843215']},\n",
       " {16: ['Accuracy: 0.8908045977011494', 'F1-Score: 0.890688660702805']},\n",
       " {18: ['Accuracy: 0.9494584837545126', 'F1-Score: 0.9494162916585143']},\n",
       " {20: ['Accuracy: 0.8556701030927835', 'F1-Score: 0.8549145299145299']},\n",
       " {22: ['Accuracy: 0.8530701754385965', 'F1-Score: 0.8530355433480687']},\n",
       " {24: ['Accuracy: 0.8823529411764706', 'F1-Score: 0.8822510822510823']},\n",
       " {26: ['Accuracy: 0.7041666666666667', 'F1-Score: 0.7035439029906574']},\n",
       " {28: ['Accuracy: 0.8103448275862069', 'F1-Score: 0.8102884329467738']},\n",
       " {30: ['Accuracy: 0.9682539682539683', 'F1-Score: 0.9682407407407407']},\n",
       " {32: ['Accuracy: 0.7987804878048781', 'F1-Score: 0.7960429621254945']},\n",
       " {34: ['Accuracy: 0.9470588235294117', 'F1-Score: 0.9470264895250942']},\n",
       " {36: ['Accuracy: 0.8769230769230769', 'F1-Score: 0.8765651890095543']},\n",
       " {38: ['Accuracy: 0.8945686900958466', 'F1-Score: 0.8938361444297123']},\n",
       " {40: ['Accuracy: 0.8575803981623277', 'F1-Score: 0.8562848319193497']}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: ['Accuracy: 0.9087893864013267', 'F1-Score: 0.9087080391428217']},\n",
       " {4: ['Accuracy: 0.8422090729783037', 'F1-Score: 0.8420314690761801']},\n",
       " {6: ['Accuracy: 0.9683615819209039', 'F1-Score: 0.9683401984934126']},\n",
       " {8: ['Accuracy: 0.6754385964912281', 'F1-Score: 0.6752136752136753']},\n",
       " {10: ['Accuracy: 0.9848993288590604', 'F1-Score: 0.9848921410404821']},\n",
       " {12: ['Accuracy: 0.9412955465587044', 'F1-Score: 0.9411680157038607']},\n",
       " {14: ['Accuracy: 0.9863713798977853', 'F1-Score: 0.9863624747345677']},\n",
       " {16: ['Accuracy: 0.9244264507422402', 'F1-Score: 0.9244197059552084']},\n",
       " {18: ['Accuracy: 0.9833119383825417', 'F1-Score: 0.9832762222460759']},\n",
       " {20: ['Accuracy: 0.8148893360160966', 'F1-Score: 0.8144197675173712']},\n",
       " {22: ['Accuracy: 0.9971590909090909', 'F1-Score: 0.9971590679805977']},\n",
       " {24: ['Accuracy: 0.7183098591549296', 'F1-Score: 0.7178060413354531']},\n",
       " {26: ['Accuracy: 0.8722139673105498', 'F1-Score: 0.872213685177335']},\n",
       " {28: ['Accuracy: 0.8406593406593407', 'F1-Score: 0.8398422090729785']},\n",
       " {30: ['Accuracy: 0.9978401727861771', 'F1-Score: 0.9978393563801986']},\n",
       " {32: ['Accuracy: 0.784', 'F1-Score: 0.7839446898405993']},\n",
       " {34: ['Accuracy: 0.9426605504587156', 'F1-Score: 0.9425272204792914']},\n",
       " {36: ['Accuracy: 0.9593301435406698', 'F1-Score: 0.9593112807269687']},\n",
       " {38: ['Accuracy: 0.9842873176206509', 'F1-Score: 0.9842872978283872']},\n",
       " {40: ['Accuracy: 0.7614314115308151', 'F1-Score: 0.7614229249011859']}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: ['Accuracy: 0.9540757749712974', 'F1-Score: 0.9540248086566376']},\n",
       " {4: ['Accuracy: 0.9617224880382775', 'F1-Score: 0.961720516269353']},\n",
       " {6: ['Accuracy: 0.9743888242142026', 'F1-Score: 0.9743860124695038']},\n",
       " {8: ['Accuracy: 0.8188405797101449', 'F1-Score: 0.8136645962732918']},\n",
       " {10: ['Accuracy: 0.9898648648648649', 'F1-Score: 0.9898648520118751']},\n",
       " {12: ['Accuracy: 0.9350393700787402', 'F1-Score: 0.9348553442011386']},\n",
       " {14: ['Accuracy: 0.9264705882352942', 'F1-Score: 0.9261614371590396']},\n",
       " {16: ['Accuracy: 0.9547581903276131', 'F1-Score: 0.9547048345869975']},\n",
       " {18: ['Accuracy: 0.9588477366255144', 'F1-Score: 0.9588303063160748']},\n",
       " {20: ['Accuracy: 0.9099236641221374', 'F1-Score: 0.9094373138420654']},\n",
       " {22: ['Accuracy: 0.9307535641547862', 'F1-Score: 0.930399906610633']},\n",
       " {24: ['Accuracy: 0.8888888888888888', 'F1-Score: 0.888888888888889']},\n",
       " {26: ['Accuracy: 0.9765100671140939', 'F1-Score: 0.9765100377235731']},\n",
       " {28: ['Accuracy: 0.8113207547169812', 'F1-Score: 0.8100509716470214']},\n",
       " {30: ['Accuracy: 0.9865319865319865', 'F1-Score: 0.9865311552066431']},\n",
       " {32: ['Accuracy: 0.890625', 'F1-Score: 0.8899533284205355']},\n",
       " {34: ['Accuracy: 0.9220023282887078', 'F1-Score: 0.9219308062207934']},\n",
       " {36: ['Accuracy: 0.9518652226233454', 'F1-Score: 0.9518344635715528']},\n",
       " {38: ['Accuracy: 0.87893864013267', 'F1-Score: 0.8786770481637152']},\n",
       " {40: ['Accuracy: 0.8606431852986217', 'F1-Score: 0.8599481961757558']}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict['Arousal']=arousal\n",
    "final_dict['Valence']=valence\n",
    "final_dict['Dominance']=dominance\n",
    "final_dict['Liking']=liking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list())\n",
    "df.to_csv('even_svc_ff_sl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('even_svc_ff_sl.csv', 'w') as f:\n",
    "    for key in final_dict.keys():\n",
    "        f.write(\"%s,%s\\n\"%(key,final_dict[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
